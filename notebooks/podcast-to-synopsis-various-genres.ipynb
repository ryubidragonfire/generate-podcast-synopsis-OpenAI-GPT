{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Podcast Synopsis for Various Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a succeeded deployment of \"text-davinci-003\" that supports text completion with id: text-davinci-003.\n"
     ]
    }
   ],
   "source": [
    "# id of desired_model\n",
    "desired_model = 'text-davinci-003' # suitable for text generation\n",
    "desired_capability = 'completion'\n",
    "\n",
    "# list models deployed with\n",
    "deployment_id = None\n",
    "result = openai.Deployment.list()\n",
    "\n",
    "for deployment in result.data:\n",
    "    if deployment[\"status\"] != \"succeeded\":\n",
    "        continue\n",
    "    \n",
    "    model = openai.Model.retrieve(deployment[\"model\"])\n",
    "\n",
    "    # check if desired_model is deployed, and if it has 'completion' capability\n",
    "    if model[\"id\"] == desired_model and model['capabilities'][desired_capability]:\n",
    "        deployment_id = deployment[\"id\"]\n",
    "        \n",
    "# if no model deployed, deploy one\n",
    "if not deployment_id:\n",
    "    print('No deployment with status: succeeded found.')\n",
    "\n",
    "    # Deploy the model\n",
    "    print(f'Creating a new deployment with model: {desired_model}')\n",
    "    result = openai.Deployment.create(model=desired_model, scale_settings={\"scale_type\":\"standard\"})\n",
    "    deployment_id = result[\"id\"]\n",
    "    print(f'Successfully created {desired_model} that supports text {desired_capability} with id: {deployment_id}.')\n",
    "else:\n",
    "    print(f'Found a succeeded deployment of \"{desired_model}\" that supports text {desired_capability} with id: {deployment_id}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text chunks generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generator that split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def chunk_generator(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_api(document, prompt_postfix, max_tokens):\n",
    "    prompt = prompt_postfix.replace('<document>',document)\n",
    "    #print(f'>>> prompt : {prompt}')\n",
    "\n",
    "    response = openai.Completion.create(  \n",
    "    deployment_id=deployment_id, \n",
    "    prompt=prompt,\n",
    "    temperature=0.5,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1,\n",
    "    frequency_penalty=1,\n",
    "    presence_penalty=1,\n",
    "    stop='###')\n",
    "\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(content, prompt_postfix):\n",
    "    import tiktoken\n",
    "\n",
    "    synopsis_chunck = []\n",
    "    n = 2000 # max tokens for chuncking\n",
    "    max_tokens = 1000 # max tokens for response\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "    # Generate chunkcs    \n",
    "    chunks = chunk_generator(content, n, tokenizer)\n",
    "\n",
    "    # Decode chunk of text\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    # Request api\n",
    "    for chunk in text_chunks:\n",
    "        synopsis_chunck.append(request_api(chunk, prompt_postfix, max_tokens))\n",
    "        #print(chunk)\n",
    "        #print('>>> synopsis: \\n' + synopsis_chunck[-1])\n",
    "\n",
    "    # Synopsis\n",
    "    synopsis = ' '.join(synopsis_chunck)\n",
    "\n",
    "    return synopsis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre : Comedy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no further information provided in the prompt, the response is rather formal and dry for the genre of comedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/comedy-booking-online-transcript.txt\"\n",
    "\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# convert list to str\n",
    "content = ' '.join(content) \n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Michael McKintyre talks about the difficulties of buying tickets online and how it can take an hour or more to get through all the steps. He also complains about having to enter his e-mail address, confirm it, and agree to various conditions. He reminisces about when passwords only had one part and jokes that he doesn't remember his own security questions. Finally, he expresses confusion over why people would pay for a restricted view ticket as it is cheaper than getting a full view seat.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nSummarise the transcript of a podcast above into a synopsis. \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more information may help in achieving a more desirable results:\n",
    "- genre\n",
    "- desired style\n",
    "\n",
    "Be creative and explicit about the desired outcome when desiging the prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Michael McKintyre is back with a new stand-up comedy show, and he's sure to have you in stitches! Join him as he hilariously recounts his struggles with booking tickets online, trying to remember passwords, security questions and more. From the hilarious absurdity of having Angola on the list of countries when buying tickets for a local cinema, to being asked for your email address just to buy a toaster from Argos - Michael will make you laugh at all the ridiculousness that comes with modern life.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nCreate a synopsis to capture audience curiosy and heighten anticipation. This is a stand-up comedy. \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre : Informational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/ft-interview-transcription.txt\"\n",
    "\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# convert list to str\n",
    "content = ' '.join(content) \n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Robert Armstrong, the FTâ€™s US financial commentator, discusses the collapse of Silicon Valley Bank and why it is not a repeat of 2008. He explains that two factors led to SVB's downfall: bad decisions at the bank and a rapid increase in interest rates. Rob also talks about how banks operate and how SVB was dealing with an influx of deposits while their costs were rising due to increased interest rates. He then goes on to explain the government's role in protecting depositors' money as well as why there is a two-tier regulatory system for banking in the US. Finally, he emphasizes that panic should be avoided and that most individual banks are in good shape. \\nIn this interview, Robert Armstrong discusses the two-tier system of regulation for banks in the United States since 2008 and how it affects banking today. He explains that while regulators may have to think more carefully about risk posed by securities on balance sheets, a perfectly safe banking system is impossible. He suggests that entrepreneurs and investors ask questions about their bank's capital structure before investing money and encourages them to look beyond appearances when selecting a bank. Armstrong also predicts consequences from the current rate risk crisis, such as slowing economic growth due to investor wariness towards putting equity into banks. However, he believes that because of regulations put in place after 2008, fewer banks will blow up than expected.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nGenerate a synopsis from the transcription of an interview.  \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Robert Armstrong, the FT's US financial commentator, has been closely following the collapse of Silicon Valley Bank. He explains why this case is different from 2008 and how two factors - bad decisions at SVB and a rapid increase in interest rates - led to its downfall. With deposits quadrupling in a couple of years, their profits started to disappear as their cost of funding rose. Will other banks be affected? Let's find out! In this Behind the Money episode, Robert Armstrong shares his insights on the lessons learned from the 2008 financial crisis and its implications for banking regulation. He talks about why there is still a risk of bank failures despite stringent regulations, and suggests that entrepreneurs should be asking their banks key questions to assess their capital structure. What does all this mean for the future of banking? Let's find out!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nGenerate a short synopsis from the transcription of an interview, such that it trigger curiosity, include a thought provoking question. Add \"Let's find out!\" at the end.  \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
